{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2a2cdf",
   "metadata": {},
   "source": [
    "# Input_data package usage example\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Print available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775461b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.input_data import create_dataset, SupportedDatasets, list_supported_datasets\n",
    "\n",
    "datasets = list_supported_datasets()\n",
    "print(f\"Supported datasets: {', '.join(datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01e17b",
   "metadata": {},
   "source": [
    "### Set data root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root = Path.cwd().parent / \"data\" # src -> ml-sandbox -> ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b459879",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab73db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*10} Working with {SupportedDatasets.MNIST.name} {'='*10}\\n\")\n",
    "\n",
    "mnist_dataset = create_dataset(SupportedDatasets.MNIST, root=root, force_download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d1770",
   "metadata": {},
   "source": [
    "### Print dataset information and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset information and show random samples\n",
    "mnist_dataset.print_info()\n",
    "\n",
    "# Visualize some examples\n",
    "mnist_dataset.show_illustrative_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b229b",
   "metadata": {},
   "source": [
    "## FASHION-MNIST Dataset\n",
    "\n",
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*10} Working with {SupportedDatasets.FASHION_MNIST.name} {'='*10}\\n\")\n",
    "\n",
    "fashion_mnist_dataset = create_dataset(SupportedDatasets.FASHION_MNIST, root=root, force_download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae71944",
   "metadata": {},
   "source": [
    "### Print dataset information and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset information and show random samples\n",
    "fashion_mnist_dataset.print_info()\n",
    "\n",
    "# Visualize some examples\n",
    "fashion_mnist_dataset.show_illustrative_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648bfc6",
   "metadata": {},
   "source": [
    "## CIFAR-10 Dataset\n",
    "\n",
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc743de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*10} Working with {SupportedDatasets.CIFAR10.name} {'='*10}\\n\")\n",
    "\n",
    "cifar10_dataset = create_dataset(SupportedDatasets.CIFAR10, root=root, force_download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee226c4",
   "metadata": {},
   "source": [
    "### Print dataset information and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset information and show random samples\n",
    "cifar10_dataset.print_info()\n",
    "\n",
    "# Visualize some examples\n",
    "cifar10_dataset.show_illustrative_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e65e8",
   "metadata": {},
   "source": [
    "## New Dataset\n",
    "\n",
    "Test out a new implementation of the `ManagedDataset` interface in the following steps:\n",
    "\n",
    "### Specify dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.input_data.structure import DatasetInfo\n",
    "\n",
    "PLACEHOLDER_INFO = DatasetInfo(\n",
    "    name=\"Placeholder\",\n",
    "    description=\"Placeholder dataset\",\n",
    "    classes=[\"class1\", \"class2\", \"class3\", \"class4\", \"class5\"],\n",
    "    num_classes=5,\n",
    "    input_shape=(3, 32, 32),\n",
    "    license=\"\",\n",
    "    citation=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116a6d7",
   "metadata": {},
   "source": [
    "### Specify dowloads information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.input_data.downloaders import DownloadInfo\n",
    "\n",
    "PLACEHOLDER_DOWNLOADS = [\n",
    "    DownloadInfo(\n",
    "        name=\"Placeholder\",\n",
    "        filename=\"placeholder.tar.gz\",\n",
    "        urls=[\n",
    "            \"https://example.com/placeholder.tar.gz\",\n",
    "            \"https://example2.com/placeholder.tar.gz\"\n",
    "        ],\n",
    "        md5=\"d41d8cd98f00b204e9800998ecf8427e\",  # Example MD5 for an empty file\n",
    "        description=\"Placeholder\"\n",
    "    ),\n",
    "    # Add more DownloadInfo instances as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147e810",
   "metadata": {},
   "source": [
    "### Implement the class interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, override\n",
    "import numpy as np\n",
    "from src.input_data.structure import ManagedDataset\n",
    "\n",
    "class PlaceholderDataset(ManagedDataset):\n",
    "    \"\"\"\n",
    "    Placeholder dataset with automatic download and flexible storage.\n",
    "\n",
    "    Loads ALL Placeholder data (train + test) into a unified dataset.\n",
    "    Use get_dataloaders() to split into train/val/test sets.\n",
    "    \n",
    "    Returns:\n",
    "        sample: torch.Tensor of shape (1, x, x) with values in [0, 1]\n",
    "        target: int class label (0-9)\n",
    "    \"\"\"\n",
    "    \n",
    "    @override\n",
    "    @property\n",
    "    def download_infos(self) -> List[DownloadInfo]:\n",
    "        return PLACEHOLDER_DOWNLOADS\n",
    "\n",
    "    @override\n",
    "    @property\n",
    "    def dataset_name(self) -> str:\n",
    "        return \"placeholder\"\n",
    "\n",
    "    @override\n",
    "    @property\n",
    "    def dataset_info(self) -> DatasetInfo:\n",
    "        return PLACEHOLDER_INFO\n",
    "    \n",
    "    @override\n",
    "    def _load_raw_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load raw MNIST data from downloaded files.\"\"\"\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Load training data\n",
    "        file_path = self.dataset_root / \"placeholder.tar.gz\"\n",
    "        \n",
    "        # --- Define the whole extraction and loading logic here ---\n",
    "    \n",
    "        # Combine all data and normalize to 0-1 range\n",
    "        combined_data = np.concatenate(all_images, axis=0).astype(np.float32) / 255.0\n",
    "        combined_labels = np.concatenate(all_labels, axis=0)\n",
    "        \n",
    "        print(f\"Loaded complete Placeholder dataset: {len(combined_data):,} samples \")\n",
    "        \n",
    "        return combined_data, combined_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
