{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6437dc74",
   "metadata": {},
   "source": [
    "# Sample Autoencoder\n",
    "\n",
    "In this notebook a sample autoencoder model is presented, showcasing the functionalities from the source utility files, upon which all model implementations can be built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d38fd",
   "metadata": {},
   "source": [
    "## Add project root to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "src_root = Path.cwd().parent  # notebooks -> ml-sandbox\n",
    "\n",
    "# Add source root to sys.path\n",
    "import sys\n",
    "\n",
    "if str(src_root) not in sys.path:\n",
    "    sys.path.append(str(src_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b550a",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3db0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import (\n",
    "    MnistDataset,\n",
    "    Regressor,\n",
    "    Autoencoder,\n",
    ")\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "from torch import nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a58ce1",
   "metadata": {},
   "source": [
    "## Define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59df917",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict(\n",
    "    # Training hyperparameters\n",
    "    batch_size=64,\n",
    "    num_epochs=10,\n",
    "    # Model hyperparameters\n",
    "    learning_rate=1e-3,\n",
    "    regularization_weight=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad791a",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d06494",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MnistDataset()\n",
    "dataloaders = mnist.get_dataloaders(\n",
    "    train_split=0.6, val_split=0.2, test_split=0.2, batch_size=hparams[\"batch_size\"]\n",
    ")\n",
    "\n",
    "model = Autoencoder(dims=[28 * 28, 128, 64, 32], sigma=nn.LeakyReLU)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams[\"learning_rate\"])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    ")\n",
    "\n",
    "trainer = Regressor(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    scheduler_metric=True,\n",
    "    loss_function=\"MSE\",\n",
    ").initialize_regularization(method=\"L2\", weight=hparams[\"regularization_weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599da0e",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db612b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.train(\n",
    "    train_dataloader=dataloaders[\"train\"],\n",
    "    validation_dataloader=dataloaders[\"val\"],\n",
    "    epochs=hparams[\"num_epochs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089a9d6",
   "metadata": {},
   "source": [
    "## Print training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b83e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 20 + \" Training Results \" + \"=\" * 20)\n",
    "\n",
    "print(f\"Final training loss: {results.train_loss:.4f}\")\n",
    "print(f\"Final validation loss: {results.validation_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dccb7a",
   "metadata": {},
   "source": [
    "## Show sample reconstruction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b995aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from src.input_data.structure.base import ManagedDataset\n",
    "from src.input_data.structure.plots import plot_samples\n",
    "\n",
    "\n",
    "def show_random_samples(\n",
    "    dataset: ManagedDataset, model: nn.Module, num_samples: int = 8, figsize=(12, 8)\n",
    ") -> None:\n",
    "    \"\"\"Display random samples from the dataset.\"\"\"\n",
    "    if len(dataset) == 0:\n",
    "        print(\"Dataset is empty!\")\n",
    "        return\n",
    "\n",
    "    # Set model to evaluation mode and move to a proper device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Select random indices\n",
    "    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in indices:\n",
    "            image, target_idx = dataset[idx]\n",
    "\n",
    "            image = image.to(device)\n",
    "\n",
    "            image_reconstructed = model(image.unsqueeze(0)).squeeze(0)\n",
    "            image_list = [image, image_reconstructed]\n",
    "            label_list = [\"Original\", \"Reconstructed\"]\n",
    "\n",
    "            plot_samples(\n",
    "                image_list,\n",
    "                labels=label_list,\n",
    "                suptitle=f\"Random samples of the {dataset.dataset_info.name} dataset\",\n",
    "            )\n",
    "\n",
    "\n",
    "show_random_samples(mnist, model, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-sandbox (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
